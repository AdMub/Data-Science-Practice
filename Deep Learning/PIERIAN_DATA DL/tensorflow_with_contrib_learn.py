# -*- coding: utf-8 -*-
"""TensorFlow with Contrib.Learn

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZMrlBSDECBz_Aelw1MmlbXO12NE_Enfa

**Theory:**
This code demonstrates how to train and evaluate a Deep Neural Network (DNN) classifier on the Iris dataset using TensorFlow. The steps involved include data loading, preprocessing, model creation, training, and evaluation.

**1. Data Loading:**
The Iris dataset is loaded using sklearn.datasets.load_iris(). This dataset contains 150 samples of iris flowers with four features: sepal length, sepal width, petal length, and petal width. Each sample is labeled with one of three classes representing different iris species.

**2. Data Splitting:**
The dataset is split into training and testing sets using train_test_split() from sklearn.model_selection. This ensures that 70% of the data is used for training and 30% for testing.

**3. Feature Columns:**
TensorFlow feature columns are defined for each of the four features in the dataset. These feature columns help the model understand the input data structure.

**4. Input Functions:**
Two input functions, train_input_fn and eval_input_fn, are defined. These functions create TensorFlow datasets from the training and testing data, respectively. The datasets are shuffled and batched to ensure efficient training and evaluation.

**5. Model Creation:**
A DNNClassifier is created using TensorFlow's tf.estimator.DNNClassifier. This classifier has three hidden layers with 10, 20, and 10 units, respectively, and three output classes (one for each iris species).

**6. Model Training:**
The model is trained using the classifier.train() method, which takes the training input function and the number of training steps as arguments. The training input function provides batches of training data to the model.

**7. Model Evaluation:**
The model is evaluated on the test set using the classifier.evaluate() method. The evaluation input function provides batches of test data to the model, and the model's accuracy on the test set is printed.

**8. Summary:**
This code provides a complete workflow for training and evaluating a DNN classifier on a simple dataset using TensorFlow. The key steps involve data preparation, model definition, training, and evaluation, all implemented using TensorFlow's high-level Estimator API.

# **Training and Evaluating a DNN Classifier on the Iris Dataset Using TensorFlow**
"""

from sklearn.datasets import load_iris

iris = load_iris()

iris

iris.keys()

X = iris['data']

y = iris['target']

y

y.dtype

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

# Feature columns
feature_columns = [tf.feature_column.numeric_column(key=str(i)) for i in range(X.shape[1])]

# DNNClassifier
classifier = tf.estimator.DNNClassifier(
    feature_columns=feature_columns,
    hidden_units=[10, 20, 10],
    n_classes=3
)

# Training input function
train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(
    x={str(i): X_train[:, i] for i in range(X.shape[1])},
    y=y_train,
    batch_size=20,
    num_epochs=None,
    shuffle=True
)

# Train the model
classifier.train(input_fn=train_input_fn, steps=2000) # Use .train() instead of .fit() for TensorFlow Estimators

# Define the input function for evaluation
def eval_input_fn():
    dataset = tf.data.Dataset.from_tensor_slices(({str(i): X_test[:, i] for i in range(X_test.shape[1])}, y_test))
    dataset = dataset.batch(32)
    return dataset

# Convert the generator to a list
iris_predictions = list(classifier.predict(input_fn=eval_input_fn))

# Extract the predicted class labels (assuming they are in a key called 'class_ids')
iris_predictions = [pred['class_ids'][0] for pred in iris_predictions]

# Train the model
classifier.train(input_fn=train_input_fn, steps=2000) # Use .train() instead of .fit() for TensorFlow Estimators

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print(confusion_matrix(y_test, iris_predictions))
print(classification_report(y_test, iris_predictions))
print(accuracy_score(y_test, iris_predictions))

import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.datasets import load_iris

# Load iris dataset
iris = load_iris()
X, y = iris.data, iris.target

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature columns
feature_columns = [tf.feature_column.numeric_column(key=str(i)) for i in range(X.shape[1])]

# DNNClassifier
classifier = tf.estimator.DNNClassifier(
    feature_columns=feature_columns,
    hidden_units=[10, 20, 10],
    n_classes=3
)

# Training input function
train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(
    x={str(i): X_train[:, i] for i in range(X.shape[1])},
    y=y_train,
    batch_size=20,
    num_epochs=None,
    shuffle=True
)

# Train the classifier
classifier.train(input_fn=train_input_fn, steps=2000)

# Prediction input function
test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(
    x={str(i): X_test[:, i] for i in range(X.shape[1])},
    num_epochs=1,
    shuffle=False
)

# Predict
iris_predictions = list(classifier.predict(input_fn=test_input_fn))
predicted_classes = [p['class_ids'][0] for p in iris_predictions]

# Evaluation
print(confusion_matrix(y_test, predicted_classes))
print(classification_report(y_test, predicted_classes))
print(accuracy_score(y_test, predicted_classes))



import tensorflow as tf
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# Load the Iris dataset
iris = load_iris()
X = iris.data
y = iris.target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Define feature columns
feature_columns = [
    tf.feature_column.numeric_column('sepal_length'),
    tf.feature_column.numeric_column('sepal_width'),
    tf.feature_column.numeric_column('petal_length'),
    tf.feature_column.numeric_column('petal_width')
]

# Define the input function
def train_input_fn():
    # Create a dataset from the features and labels
    dataset = tf.data.Dataset.from_tensor_slices((
        {'sepal_length': X_train[:, 0],
         'sepal_width': X_train[:, 1],
         'petal_length': X_train[:, 2],
         'petal_width': X_train[:, 3]},
        y_train
    ))
    # Shuffle and batch the data
    dataset = dataset.shuffle(1000).batch(32)
    return dataset

# Create the DNNClassifier
classifier = tf.estimator.DNNClassifier(
    feature_columns=feature_columns,
    hidden_units=[10, 20, 10],
    n_classes=3
)

# Train the model
classifier.train(input_fn=train_input_fn, steps=2000)

# Define the input function for evaluation
def eval_input_fn():
    dataset = tf.data.Dataset.from_tensor_slices((
        {'sepal_length': X_test[:, 0],
         'sepal_width': X_test[:, 1],
         'petal_length': X_test[:, 2],
         'petal_width': X_test[:, 3]},
        y_test
    ))
    dataset = dataset.batch(32)
    return dataset

# Evaluate the model on the test set
eval_result = classifier.evaluate(input_fn=eval_input_fn)
print(f"Test set accuracy: {eval_result['accuracy']:.4f}")

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf

iris = load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

def train_input_fn():
    # Create a StandardScaler object
    scaler = StandardScaler()

    # Fit the scaler on the training data and transform it
    X_train_scaled = scaler.fit_transform(X_train)

    # Create a TensorFlow Dataset from the scaled training data
    dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train))

    # Shuffle, batch, and repeat the dataset
    dataset = dataset.shuffle(1000).batch(32).repeat()

    return dataset


# Convert the generator to a list
iris_predictions = list(classifier.predict(input_fn=eval_input_fn))

# Extract the predicted class labels (assuming they are in a key called 'class_ids')
iris_predictions = [pred['class_ids'][0] for pred in iris_predictions]

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print(confusion_matrix(y_test, iris_predictions))
print(classification_report(y_test, iris_predictions))
print(accuracy_score(y_test, iris_predictions))

# Tensorflow 1.0x

 import tensorflow.contrib.learn.python.learn as learn

 classifier = learn.DNNClassifier(hidden_units=[10, 20, 10], n_classes=3)
 classifier.fit(X_train, y_train, steps=2000, batch_size=20)

iris_predictions = classifier.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print(confusion_matrix(y_test, iris_predictions))
print(classification_report(y_test, iris_predictions))
print(accuracy_score(y_test, iris_predictions))

